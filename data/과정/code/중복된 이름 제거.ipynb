{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b802b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¤€ íŒŒì¼: ì„œìš¸êµí†µê³µì‚¬_ë°ì´í„°_íœ´ì¼ìˆ˜ì •ë³¸_2023ë…„.csv\n",
      "âœ… ê¸°ì¤€ ì—­ ê°œìˆ˜: 247\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_ë°ì´í„°_íœ´ì¼ìˆ˜ì •ë³¸_2023ë…„_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_ë°ì´í„°_íœ´ì¼ìˆ˜ì •ë³¸_2022ë…„_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_ë°ì´í„°_íœ´ì¼ìˆ˜ì •ë³¸_2021ë…„_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_ë°ì´í„°_íœ´ì¼ìˆ˜ì •ë³¸_2020ë…„_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_1~8í˜¸ì„ ì¼ë³„ì—­ë³„ì‹œê°„ëŒ€ë³„ìŠ¹í•˜ì°¨ì¸ì›_2019ë…„_íœ´ì¼ìˆ˜ì •ë³¸_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_1~8í˜¸ì„ ì¼ë³„ì—­ë³„ì‹œê°„ëŒ€ë³„ìŠ¹í•˜ì°¨ì¸ì›_2018ë…„_íœ´ì¼ìˆ˜ì •ë³¸_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_1~8í˜¸ì„ ì¼ë³„ì—­ë³„ì‹œê°„ëŒ€ë³„ìŠ¹í•˜ì°¨ì¸ì›_2017ë…„_íœ´ì¼ìˆ˜ì •ë³¸_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_1~8í˜¸ì„ ì¼ë³„ì—­ë³„ì‹œê°„ëŒ€ë³„ìŠ¹í•˜ì°¨ì¸ì›_2016ë…„_íœ´ì¼ìˆ˜ì •ë³¸_ì´ë¦„í†µì¼í™”.csv\n",
      "âœ… ì €ì¥ ì™„ë£Œ: ../samename_data\\ì„œìš¸êµí†µê³µì‚¬_1~8í˜¸ì„ ì¼ë³„ì—­ë³„ì‹œê°„ëŒ€ë³„ìŠ¹í•˜ì°¨ì¸ì›_2015ë…„_íœ´ì¼ìˆ˜ì •ë³¸_ì´ë¦„í†µì¼í™”.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "csv_dir = '../holiday_data'\n",
    "refined_dir = '../samename_data'\n",
    "os.makedirs(refined_dir, exist_ok=True)\n",
    "\n",
    "# ğŸ—‘ï¸ ê¸°ì¡´ ì •ì œ íŒŒì¼ ì‚­ì œ\n",
    "refined_files = glob.glob(os.path.join(csv_dir, '*_ì´ë¦„í†µì¼í™”.csv')) + glob.glob(os.path.join(refined_dir, '*_ì´ë¦„í†µì¼í™”.csv'))\n",
    "for file_path in refined_files:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {file_path} â†’ {e}\")\n",
    "\n",
    "# ğŸ“„ CSV íŒŒì¼ ëª©ë¡ (ì •ì œ ì „, \"_ì´ë¦„í†µì¼í™”.csv\" ì œì™¸)\n",
    "files = [f for f in glob.glob(os.path.join(csv_dir, '*.csv')) if '_ì´ë¦„í†µì¼í™”.csv' not in f]\n",
    "files.sort(reverse=True)\n",
    "\n",
    "# ğŸ“Œ 2023ë…„ ê¸°ì¤€ ì—­ëª… í™•ë³´\n",
    "base_file = next((f for f in files if '2023ë…„' in f), None)\n",
    "if base_file is None:\n",
    "    raise ValueError(\"âŒ 2023ë…„ ê¸°ì¤€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì— '2023'ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ê¸°ì¤€ íŒŒì¼ ì½ê¸° (ì—­ë²ˆí˜¸ë¥¼ ë¬¸ìì—´ë¡œ)\n",
    "base_df = pd.read_csv(base_file, encoding='cp949', dtype={'ì—­ë²ˆí˜¸': str})\n",
    "if 'ì—­ë²ˆí˜¸' not in base_df.columns or 'ì—­ëª…' not in base_df.columns:\n",
    "    raise ValueError(\"âŒ 'ì—­ë²ˆí˜¸' ë˜ëŠ” 'ì—­ëª…' ì—´ì´ ê¸°ì¤€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "standard_map = base_df[['ì—­ë²ˆí˜¸', 'ì—­ëª…']].drop_duplicates().set_index('ì—­ë²ˆí˜¸')['ì—­ëª…'].to_dict()\n",
    "standard_names = set(standard_map.values())\n",
    "\n",
    "print(f\"âœ… ê¸°ì¤€ íŒŒì¼: {os.path.basename(base_file)}\")\n",
    "print(f\"âœ… ê¸°ì¤€ ì—­ ê°œìˆ˜: {len(standard_names)}\")\n",
    "\n",
    "# âœ… ì´ë¦„ ë§¤í•‘ í…Œì´ë¸” ìƒì„±\n",
    "name_mapping = {}\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, encoding='cp949', dtype={'ì—­ë²ˆí˜¸': str})\n",
    "    if 'ì—­ëª…' not in df.columns:\n",
    "        continue\n",
    "    for name in df['ì—­ëª…'].unique():\n",
    "        if name in standard_names:\n",
    "            name_mapping[name] = name\n",
    "        elif name not in name_mapping:\n",
    "            match = get_close_matches(name, standard_names, n=1, cutoff=0.9)\n",
    "            name_mapping[name] = match[0] if match else None  # Noneì´ë©´ ì‚­ì œ ëŒ€ìƒ\n",
    "\n",
    "# ğŸ” ì´ë¦„ ë§¤í•‘ ì²˜ë¦¬\n",
    "change_log = []\n",
    "delete_log = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, encoding='cp949', low_memory=False, dtype={'ì—­ë²ˆí˜¸': str})\n",
    "    if 'ì—­ë²ˆí˜¸' not in df.columns:\n",
    "        print(f\"âš ï¸ 'ì—­ë²ˆí˜¸' ì—´ì´ ì—†ëŠ” íŒŒì¼: {os.path.basename(file)}\")\n",
    "        continue\n",
    "\n",
    "    original_names = df['ì—­ëª…'].copy() if 'ì—­ëª…' in df.columns else pd.Series([None]*len(df))\n",
    "\n",
    "    # ë§¤í•‘: ì—­ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¤€ ì—­ëª…ìœ¼ë¡œ í†µì¼\n",
    "    df['ì—­ëª…'] = df['ì—­ë²ˆí˜¸'].map(standard_map)\n",
    "\n",
    "    # ì‚­ì œ ëŒ€ìƒ: ê¸°ì¤€ì— ì—†ëŠ” ì—­ë²ˆí˜¸ (ì¦‰, map ê²°ê³¼ê°€ NaNì¸ ê²½ìš°)\n",
    "    delete_rows = df[df['ì—­ëª…'].isna()]\n",
    "    df = df[df['ì—­ëª…'].notna()].reset_index(drop=True)\n",
    "    \n",
    "    # ì €ì¥\n",
    "    new_filename = os.path.splitext(os.path.basename(file))[0] + \"_ì´ë¦„í†µì¼í™”.csv\"\n",
    "    save_path = os.path.join(refined_dir, new_filename)\n",
    "    df.to_csv(save_path, index=False, encoding='cp949')\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9e206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
