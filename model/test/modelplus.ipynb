{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279657d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ë¡œë“œ\n",
    "scaler = joblib.load(\"./my_scaler.1line.pkl\")\n",
    "model = load_model(\"./my_dl_model.1line.keras\")\n",
    "exit_df = pd.read_csv(\n",
    "    \"../../data/ê³¼ì •/3.ë¹ ë¥¸ì¶œìž…êµ¬/ì „ì² ì—­ ê°€ê¹Œìš´ íƒ‘ìŠ¹êµ¬_ê°€ê³µ_ìµœì¢….csv\", encoding=\"euc-kr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d3d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_exit_weights(exit_str, num_cars=10):\n",
    "    weights = np.ones(num_cars)\n",
    "    if pd.isna(exit_str):\n",
    "        return weights\n",
    "    for val in str(exit_str).split(\",\"):\n",
    "        val = val.strip()\n",
    "        if \"-\" in val:\n",
    "            try:\n",
    "                car = int(val.split(\"-\")[0])\n",
    "                if 1 <= car <= num_cars:\n",
    "                    weights[car - 1] += 1\n",
    "            except:\n",
    "                continue\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0673f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exit_weights(exit_df, station_name, direction, num_cars=10):\n",
    "    row = exit_df[exit_df[\"ì—­ëª…\"] == station_name]\n",
    "    if row.empty:\n",
    "        print(f\"[âš ï¸] '{station_name}' ì—­ ì—†ìŒ\")\n",
    "        return np.ones(num_cars)\n",
    "\n",
    "    col = \"ê°€ê¹Œìš´ ì¶œêµ¬\" if direction == \"ìƒí–‰\" else \"ê°€ê¹Œìš´ ì¶œêµ¬.1\"\n",
    "\n",
    "    if col not in row.columns:\n",
    "        print(f\"[âš ï¸] ì¶œêµ¬ ì¹¼ëŸ¼ ì—†ìŒ: {col}\")\n",
    "        return np.ones(num_cars)\n",
    "\n",
    "    return parse_exit_weights(row.iloc[0][col], num_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0deb3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_name = input(\"ðŸš‰ ì—­ëª… ìž…ë ¥: \").strip()\n",
    "hour = int(input(\"ðŸ• ì‹œê°„ ìž…ë ¥ (0~23): \").strip())\n",
    "weekday = int(input(\"ðŸ“… í‰ì¼=0, ì£¼ë§=1: \").strip())\n",
    "direction = input(\"â†•ï¸ ë°©í–¥ ìž…ë ¥ (ìƒí–‰/í•˜í–‰): \").strip()\n",
    "\n",
    "# ì—­ë²ˆí˜¸ ë§¤í•‘ (ì¶œìž…êµ¬ CSVì—ì„œ ìžë™ ê°€ì ¸ì˜¤ê¸°)\n",
    "ì—­ë²ˆí˜¸_map = exit_df.set_index(\"ì—­ëª…\")[\"ì—­ë²ˆí˜¸\"].to_dict()\n",
    "station_code = ì—­ë²ˆí˜¸_map.get(station_name, 999)\n",
    "\n",
    "if station_code == 999:\n",
    "    print(f\"[âš ï¸] '{station_name}' ì—­ë²ˆí˜¸ ì°¾ì„ ìˆ˜ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fce304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    }
   ],
   "source": [
    "# 1. 1ì°¨ ì˜ˆì¸¡ì— ì‚¬ìš©ë  ìž…ë ¥ (ìŠ¹í•˜ì°¨/í˜¼ìž¡ë„ëŠ” 0 ë˜ëŠ” None)\n",
    "X_input = np.array(\n",
    "    [\n",
    "        [\n",
    "            station_code,\n",
    "            hour,\n",
    "            weekday,\n",
    "            1 if direction == \"ìƒí–‰\" else 0,\n",
    "            1,\n",
    "            0,  # ìŠ¹í•˜ì°¨ì¸ì› (ì´ˆê¸°ê°’)\n",
    "            0,  # í˜¼ìž¡ë„ (ì´ˆê¸°ê°’)\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "scaled_input = scaler.transform(X_input)\n",
    "total_passenger = model.predict(scaled_input)[0, 0]\n",
    "\n",
    "# ìŒìˆ˜ê°’ ë°©ì§€\n",
    "total_passenger = max(total_passenger, 0)\n",
    "\n",
    "# 2. í˜¼ìž¡ë„ëŠ” ì‚°ì‹ìœ¼ë¡œ ê³„ì‚° (ì‹¤ì œ ì •ì›ì´ í•„ìš”)\n",
    "train_capacity = 1600\n",
    "congestion = min(total_passenger / train_capacity * 100, 200)  # 200% ìƒí•œ\n",
    "\n",
    "# 3. ìŠ¹í•˜ì°¨ì¸ì›ì€, ì´ ì¸ì›ê³¼ ë¹„ë¡€í•´ ì‚°ì •í•˜ê±°ë‚˜ ë°ì´í„°, ì˜ˆì¸¡ë¡œì§ ë§ˆë ¨ (ì—†ìœ¼ë©´ 0~í‰ê· ê°’ í™œìš©)\n",
    "#    í˜¼ìž¡ë„ê°€ AIì˜ ë³„ë„ ì¶œë ¥ì¼ ê²½ìš°, pred[1] ì‚¬ìš©\n",
    "\n",
    "# í›„ì²˜ë¦¬(ë¶„ë°°)ëŠ” ë™ì¼\n",
    "\n",
    "# 4. ë¶„ë°°\n",
    "exit_weights = get_exit_weights(exit_df, station_name, direction, num_cars)\n",
    "proportions = exit_weights / exit_weights.sum()\n",
    "car_passenger = total_passenger * proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4900aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ê³„ì‚°ëœ í˜¼ìž¡ë„: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# í˜¼ìž¡ë„ ê³„ì‚°\n",
    "train_capacity = 1600  # ì—´ì°¨ ìµœëŒ€ ìˆ˜ìš© ì¸ì› (ì˜ˆ, ì—´ì°¨ 10ì¹¸ Ã— ì¹´ë‹¹ 160ëª…)\n",
    "\n",
    "congestion_rate = min((total_passenger / train_capacity) * 100, 200)  # ìƒí•œ ê°’ ì„¤ì •\n",
    "print(f\"ðŸ“Š ê³„ì‚°ëœ í˜¼ìž¡ë„: {congestion_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52b61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cars = 10\n",
    "exit_weights = get_exit_weights(exit_df, station_name, direction, num_cars)\n",
    "proportions = exit_weights / exit_weights.sum()\n",
    "car_passenger = total_passenger * proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e31854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš‰ ì‹œì²­ ìƒí–‰ í˜¼ìž¡ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "ðŸšª 1ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 2ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 3ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 4ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 5ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 6ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 7ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 8ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 9ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n",
      "ðŸšª 10ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: 0.00ëª…\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nðŸš‰ {station_name} {direction} í˜¼ìž¡ ì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "for i, val in enumerate(car_passenger, start=1):\n",
    "    print(f\"ðŸšª {i}ë²ˆ ì¹¸ ì˜ˆìƒ íƒ‘ìŠ¹ ì¸ì›: {val:.2f}ëª…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
